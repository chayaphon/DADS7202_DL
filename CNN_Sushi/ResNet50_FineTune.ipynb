{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/chayaphon/DADS7202_DL/blob/main/CNN_Sushi/ResNet50_FineTune.ipynb\\\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all NVIDIA GPUs as avaialble.\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.cm as cmp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"Python {sys.version}\\n\" )\n",
    "print( f\"NumPy {np.__version__}\\n\" )\n",
    "%matplotlib inline\n",
    "print(f'The scikit-learn version is {sklearn.__version__}')\n",
    "print( f\"TensorFlow {tf.__version__}\" )\n",
    "print( f\"tf.keras.backend.image_data_format() = {tf.keras.backend.image_data_format()}\" )\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print( f\"TensorFlow detected { len(gpus) } GPU(s):\" )\n",
    "for i, gpu in enumerate(gpus):\n",
    "  print( f\".... GPU No. {i}: Name = {gpu.name} , Type = {gpu.device_type}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 123456 #np.random.randint(1000, 99999)\n",
    "print(seed_value)\n",
    "\n",
    "tf.random.set_seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.load('./Images Numpy/x_sushi_aburi_224x224.npz')\n",
    "x2 = np.load('./Images Numpy/x_sushi_ebi_224x224.npz')\n",
    "x3 = np.load('./Images Numpy/x_sushi_maguro_224x224.npz')\n",
    "x4 = np.load('./Images Numpy/x_sushi_salmon_224x224.npz')\n",
    "\n",
    "x1 = x1['x']\n",
    "x2 = x2['x']\n",
    "x3 = x3['x']\n",
    "x4 = x4['x']\n",
    "\n",
    "y1 = np.array([0 for i in range(172)])\n",
    "y2 = np.array([1 for i in range(172)])\n",
    "y3 = np.array([2 for i in range(172)])\n",
    "y4 = np.array([3 for i in range(172)])\n",
    "\n",
    "print(f'x1 : {x1.shape} | y1: {y1.shape}')\n",
    "print(f'x2 : {x2.shape} | y2: {y2.shape}')\n",
    "print(f'x3 : {x3.shape} | y3: {y3.shape}')\n",
    "print(f'x4 : {x4.shape} | y4: {y4.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x1, x2, x3, x4))\n",
    "y = np.concatenate((y1, y2, y3, y4))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=np.random.randint(1,100), stratify=y)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the first 10 image of x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['sushi_aburi','sushi_ebi','sushi_maguro','sushi_salmon']\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.suptitle('Training Set', y=1.02, fontsize=16, weight='bold')\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i+1).set_title(f'class {y_train[i]} : ({label[y_train[i]]})')\n",
    "  plt.imshow(x_train[i])\n",
    "  \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.suptitle('Test Set', y=1.02, fontsize=16, weight='bold')\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i+1).set_title(f'class {y_test[i]} : ({label[y_test[i]]})')\n",
    "  plt.imshow(x_test[i])\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Pre-Trained Model ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extractor = tf.keras.applications.ResNet50(weights = 'imagenet', include_top=False, input_shape = (224, 224, 3))\n",
    "x_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_diagram_model = './out/ResNet50_Model.png'\n",
    "tf.keras.utils.plot_model(\n",
    "    x_extractor, \n",
    "    to_file=file_diagram_model, \n",
    "    show_shapes=True, \n",
    "    show_dtype=False, \n",
    "    show_layer_names=True, \n",
    "    dpi=90,\n",
    "    rankdir='TB', \n",
    "    expand_nested=True \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resnet = tf.keras.applications.resnet50.preprocess_input(x_train)\n",
    "x_test_resnet = tf.keras.applications.resnet50.preprocess_input(x_test)\n",
    "\n",
    "print(x_train_resnet.shape)\n",
    "print(x_test_resnet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_augmentation(image):\n",
    "    # Random crop\n",
    "    #image = tf.image.random_crop(image, size=(100, 100, 3))  # Adjust size as needed\n",
    "    # Add noise\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "    image = image + noise\n",
    "    # Adjust contrast\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    return image\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=custom_augmentation,  # Augmentation\n",
    "    channel_shift_range=0.1,\n",
    "    samplewise_center=False,  # ResNet50 preprocessing already centers based on ImageNet mean\n",
    "    samplewise_std_normalization=True,  \n",
    "    rotation_range=30,\n",
    "    height_shift_range=5.0,\n",
    "    width_shift_range=4.0,\n",
    "    shear_range=2.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    samplewise_center=False,           # ResNet50 preprocessing already centers based on ImageNet mean\n",
    "    samplewise_std_normalization=True  # Normalize each image by its own std deviation\n",
    ")\n",
    "\n",
    "# define seed to master seed\n",
    "train_datagen.seed = seed_value\n",
    "test_datagen.seed = seed_value\n",
    "\n",
    "train_datagen.fit(x_train_resnet)\n",
    "test_datagen.fit(x_test_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=5, subset='training')\n",
    "n_show = 1   # Show 'n_show' batches of generated data (1 batch includes 5 images)\n",
    "for i, (x_batch, y_batch) in enumerate(train_generator):\n",
    "    print(f\"===== Train batch no. {i+1}/{n_show} =====\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for j in range(5):\n",
    "        plt.subplot(1, 5, j+1).set_title(y_batch[j])\n",
    "        plt.imshow(x_batch[j])\n",
    "        plt.axis(\"off\")  # remove all tick marks\n",
    "    plt.show()\n",
    "\n",
    "    if i+1 >= n_show:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = train_datagen.flow(x_train, y_train, batch_size=5, subset='validation')\n",
    "n_show = 1   # Show 'n_show' batches of generated data (1 batch includes 5 images)\n",
    "for i, (x_batch, y_batch) in enumerate(validation_generator):\n",
    "    print(f\"===== Validation batch no. {i+1}/{n_show} =====\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for j in range(5):\n",
    "        plt.subplot(1, 5, j+1).set_title(y_batch[j])\n",
    "        plt.imshow(x_batch[j])\n",
    "        plt.axis(\"off\")  # remove all tick marks\n",
    "    plt.show()\n",
    "\n",
    "    if i+1 >= n_show:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow(x_test, y_test, batch_size=5)\n",
    "n_show = 1   # Show 'n_show' batches of generated data (1 batch includes 5 images)\n",
    "for i, (x_batch, y_batch) in enumerate(test_generator):\n",
    "    print(f\"===== Test batch no. {i+1}/{n_show} =====\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for j in range(5):\n",
    "        plt.subplot(1, 5, j+1).set_title(y_batch[j])\n",
    "        plt.imshow(x_batch[j])\n",
    "        plt.axis(\"off\")  # remove all tick marks\n",
    "    plt.show()\n",
    "\n",
    "    if i+1 >= n_show:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursively freeze all layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extractor.trainable = True\n",
    "for i, layer in enumerate(x_extractor.layers):\n",
    "  print(f'Layer {i}: Name = {layer.name}, Trainable = {layer.trainable}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-freez some layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_list = ['conv5_block1_out', 'conv5_block2_', 'conv5_block3_']\n",
    "\n",
    "# for i, layer in enumerate(x_extractor.layers):\n",
    "#     if any(part in layer.name for part in layer_list):\n",
    "#         layer.trainable = True\n",
    "\n",
    "# for i, layer in enumerate(x_extractor.layers):\n",
    "#   print(f'Layer {i}: Name = {layer.name}, Trainable = {layer.trainable}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output from 'conv2_block3_out'\n",
    "conv2_block3_out = x_extractor.get_layer('conv2_block3_out').output\n",
    "\n",
    "# Custom convolutional layers\n",
    "custom = tf.keras.layers.Conv2D(filters=256, kernel_size=7, padding='same', name='custom1_conv1')(conv2_block3_out)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom1_bn1')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom1_relu1')(custom) \n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=128, kernel_size=7, padding='same', name='custom1_conv2')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom1_bn2')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom1_relu2')(custom)\n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=128, kernel_size=7, padding='same', name='custom1_conv3')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom1_bn3')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom1_relu3')(custom)\n",
    "\n",
    "custom = tf.keras.layers.MaxPooling2D(pool_size=2, name='custom1_max_pool')(custom)\n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same', name='custom2_conv1')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom2_bn1')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom2_relu1')(custom) \n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same', name='custom2_conv2')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom2_bn2')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom2_relu2')(custom)\n",
    "\n",
    "custom = tf.keras.layers.MaxPooling2D(pool_size=2, name='custom2_max_pool')(custom)\n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', name='custom3_conv1')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom3_bn1')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom3_relu1')(custom)\n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', name='custom3_conv2')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom3_bn2')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom3_relu2')(custom)\n",
    "\n",
    "custom = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, padding='same', name='custom3_conv3')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='custom3_bn3')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='custom3_relu3')(custom)\n",
    "\n",
    "custom = tf.keras.layers.MaxPooling2D(pool_size=2, name='custom3_max_pool')(custom)\n",
    "\n",
    "# Final adjustment to match the number of channels with ResNet\n",
    "custom = tf.keras.layers.Conv2D(filters=2048, kernel_size=1, padding='same', name='adjust_channels')(custom)\n",
    "custom = tf.keras.layers.BatchNormalization(name='adjust_bn')(custom)\n",
    "custom = tf.keras.layers.Activation('relu', name='adjust_relu')(custom) \n",
    "\n",
    "# Output of the 'conv4_block6_add' layer from the base model\n",
    "conv5_block1_add = x_extractor.get_layer('conv5_block1_add').output\n",
    "\n",
    "# Concatenate the custom convolutional path and the original ResNet path\n",
    "#combined = tf.keras.layers.Concatenate(name='concat_layer')([conv5_block1_add, custom])\n",
    "# Addition (if the channels match)\n",
    "combined = tf.keras.layers.Add(name='add_layer')([conv5_block1_add, custom])\n",
    "\n",
    "# Continue with ResNet50 layers from 'conv5_block1_out' onwards\n",
    "conv5_block1_out = x_extractor.get_layer('conv5_block1_out')(combined)\n",
    "conv5_block2_1_conv = x_extractor.get_layer('conv5_block2_1_conv')(conv5_block1_out)\n",
    "conv5_block2_1_bn = x_extractor.get_layer('conv5_block2_1_bn')(conv5_block2_1_conv)\n",
    "conv5_block2_1_relu = x_extractor.get_layer('conv5_block2_1_relu')(conv5_block2_1_bn)\n",
    "conv5_block2_2_conv = x_extractor.get_layer('conv5_block2_2_conv')(conv5_block2_1_relu)\n",
    "conv5_block2_2_bn = x_extractor.get_layer('conv5_block2_2_bn')(conv5_block2_2_conv)\n",
    "conv5_block2_2_relu = x_extractor.get_layer('conv5_block2_2_relu')(conv5_block2_2_bn)\n",
    "conv5_block2_3_conv = x_extractor.get_layer('conv5_block2_3_conv')(conv5_block2_2_relu)\n",
    "conv5_block2_3_bn = x_extractor.get_layer('conv5_block2_3_bn')(conv5_block2_3_conv)\n",
    "conv5_block2_add = x_extractor.get_layer('conv5_block2_add')([conv5_block1_out, conv5_block2_3_bn])\n",
    "conv5_block2_out = x_extractor.get_layer('conv5_block2_out')(conv5_block2_add)\n",
    "\n",
    "conv5_block3_1_conv = x_extractor.get_layer('conv5_block3_1_conv')(conv5_block2_out)\n",
    "conv5_block3_1_bn = x_extractor.get_layer('conv5_block3_1_bn')(conv5_block3_1_conv)\n",
    "conv5_block3_1_relu = x_extractor.get_layer('conv5_block3_1_relu')(conv5_block3_1_bn)\n",
    "conv5_block3_2_conv = x_extractor.get_layer('conv5_block3_2_conv')(conv5_block3_1_relu)\n",
    "conv5_block3_2_bn = x_extractor.get_layer('conv5_block3_2_bn')(conv5_block3_2_conv)\n",
    "conv5_block3_2_relu = x_extractor.get_layer('conv5_block3_2_relu')(conv5_block3_2_bn)\n",
    "conv5_block3_3_conv = x_extractor.get_layer('conv5_block3_3_conv')(conv5_block3_2_relu)\n",
    "conv5_block3_3_bn = x_extractor.get_layer('conv5_block3_3_bn')(conv5_block3_3_conv)\n",
    "conv5_block3_add = x_extractor.get_layer('conv5_block3_add')([conv5_block2_out, conv5_block3_3_bn])\n",
    "conv5_block3_out = x_extractor.get_layer('conv5_block3_out')(conv5_block3_add)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name='global_avg_pool')(conv5_block3_out)\n",
    "\n",
    "# Fully connected classifier layers\n",
    "x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = tf.keras.layers.Dropout(0.5, name='dropout1')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu', name='fc2')(x)\n",
    "x = tf.keras.layers.Dropout(0.5, name='dropout2')(x)\n",
    "\n",
    "# Output layer with 4 classes (multi-class classification)\n",
    "new_outputs = tf.keras.layers.Dense(4, activation='softmax', name='output_layer')(x)\n",
    "\n",
    "# Construct the modified model\n",
    "model = tf.keras.models.Model(inputs=x_extractor.inputs, outputs=new_outputs)\n",
    "\n",
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "  print(f'Layer {i}: Name = {layer.name}, Trainable = {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001) , \n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['acc'] \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, \n",
    "    to_file=file_diagram_model, \n",
    "    show_shapes=True, \n",
    "    show_dtype=False, \n",
    "    show_layer_names=True, \n",
    "    dpi=90,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_batch_size = 64\n",
    "v_batch_size = 128\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # monitor 'val_loss', 'val_acc'\n",
    "    patience=10,           # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation performance\n",
    ")\n",
    "\n",
    "# Fit the model with early stopping\n",
    "history = model.fit(\n",
    "    train_datagen.flow(x_train_resnet, y_train, batch_size=t_batch_size, subset='training'),\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    validation_data=train_datagen.flow(x_train_resnet, y_train, batch_size=v_batch_size, subset='validation'),\n",
    "    callbacks=[early_stopping]  # Include early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_datagen.flow(x_test_resnet, y_test, batch_size = 64))\n",
    "print(f'{model.metrics_names}: {results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model\n",
    "# model.save('./save/ResNet50_Base_model.h5')\n",
    "\n",
    "# # save weight\n",
    "# model.save_weights('./save/ResNet50_Base_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize history of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Train accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for x_test_vgg16\n",
    "y_pred = []\n",
    "for i in range(len(x_test_resnet)):\n",
    "    x_input = x_test_resnet[i][np.newaxis, ...]\n",
    "    y_pred.append(np.argmax(model.predict(x_input)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ax = sns.heatmap(cm, annot=True, fmt='g', xticklabels=label, yticklabels=label, linewidths=.5)\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred, target_names=label)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  y_pred = model.predict(x_test_resnet[i].reshape(1,224,224,3))\n",
    "  plt.imshow(x_test[i])\n",
    "  plt.title(f'x_test[{i}]: predict = {np.argmax(y_pred)} ({label[np.argmax(y_pred)]}) , actual = {y_test[i]} ({label[int(y_test[i])]})')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "preprocess_input = tf.keras.applications.resnet.preprocess_input\n",
    "last_conv_layer_name = \"conv5_block3_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "          last_conv_layer_output, preds = grad_model(img_array)\n",
    "          if pred_index is None:\n",
    "              pred_index = tf.argmax(preds[0])\n",
    "          class_channel = preds[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "    \n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"./out/cam.jpg\", alpha=0.8):\n",
    "      img = img_path\n",
    "\n",
    "      # Rescale heatmap to a range 0-255\n",
    "      heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "      # Use jet colormap to colorize heatmap\n",
    "      jet = cmp.get_cmap(\"jet\")\n",
    "\n",
    "      # Use RGB values of the colormap\n",
    "      jet_colors = jet(np.arange(256))[:, :3]\n",
    "      jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "      # Create an image with RGB colorized heatmap\n",
    "      jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "      jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "      jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "      # Superimpose the heatmap on original image\n",
    "      superimposed_img = jet_heatmap * alpha + img\n",
    "      superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "      # Save the superimposed image\n",
    "      superimposed_img.save(cam_path)\n",
    "\n",
    "      # Display Grad CAM\n",
    "      display(Image(cam_path))\n",
    "\n",
    "for i in range(5):\n",
    "  c = np.random.randint(0,len(x_test)-1)\n",
    "  img_path = x_test[c]\n",
    "  img_array = preprocess_input(img_path)\n",
    "  model.layers[-1].activation = None\n",
    "  preds = model.predict(img_array.reshape(-1,224,224,3))\n",
    "  print(f\"Predicted: {label[np.argmax(preds)]} | Actual: {label[y_test[c]]} \")\n",
    "  heatmap = make_gradcam_heatmap(img_array.reshape(1,224,224,3), model, last_conv_layer_name)\n",
    "  save_and_display_gradcam(img_path, heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DADS7202",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
